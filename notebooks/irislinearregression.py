# -*- coding: utf-8 -*-
"""irisLinearRegression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LgDkcUU36ZljFlVIEbG4QdKd28pr8btR
"""

!pip install scipy
!pip install seaborn

import numpy as np
import pandas as pd

# Commented out IPython magic to ensure Python compatibility.
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats, integrate
from sklearn import metrics
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
# %matplotlib inline
pd.options.display.float_format = '{:.2f}'.format
plt.rcParams['figure.figsize'] = (8,6)
plt.rcParams['font.size'] = 14

iris = pd.read_csv("/content/sample_data/iris.csv")
iris.head()

dfSummary = iris.describe()
dfSummary

boxplot = iris.plot(kind = 'box', subplots = True, layout = (2,3), sharex = False, sharey = False, colormap = 'bwr', figsize = (15,10))

a = sns.lmplot(x = 'sepal.length', y = 'sepal.width', data = iris, aspect = 1.5, scatter_kws = {'alpha':0.2})
b = sns.lmplot(x = 'petal.length', y = 'petal.width', data = iris, aspect = 1.5, scatter_kws = {'alpha':0.2})
c = sns.lmplot(x = 'petal.length', y = 'sepal.width', data = iris, aspect = 1.5, scatter_kws = {'alpha':0.2})

scatter = pd.plotting.scatter_matrix(iris, figsize = (15,10))

scatterplot = sns.pairplot(iris, hue = "variety")

inputCols = ['sepal.width']
outputVariable = ['sepal.length']
X = iris[inputCols]
Y = iris[outputVariable]

linreg = LinearRegression()
linreg.fit(X, Y)
print(linreg.intercept_)
print(linreg.coef_)
print("\n")
print('sepal.length =' + str(linreg.coef_) + '*sepal.width + ' + str(linreg.intercept_))
print('\n')
print('Holding constant fixed, a 1 cm increase in sepalWidth lead to decrease in sepalLength by ' + str(linreg.coef_) + ' cm')

inputCols = ['petal.width']
outputVariable = ['sepal.length']
X = iris[inputCols]
Y = iris[outputVariable]

linreg = LinearRegression()
linreg.fit(X, Y)
print(linreg.intercept_)
print(linreg.coef_)
print("\n")
print('sepal.length =' + str(linreg.coef_) + '*petal.width + ' + str(linreg.intercept_))
print('\n')
print('Holding constant fixed, a 1 cm increase in petalWidth lead to decrease in sepalLength by ' + str(linreg.coef_) + ' cm')

inputCols = ['petal.width','petal.length','sepal.width']
outputVariable = ['sepal.length']
X = iris[inputCols]
Y = iris[outputVariable]

linreg = LinearRegression()
linreg.fit(X, Y)
print(linreg.intercept_)
print(linreg.coef_)
print("\n")
print('sepal.length =' + str(linreg.coef_) + '*indVars + ' + str(linreg.intercept_))
print('\n')
print('Holding constant fixed, a 1 cm increase in indvars' + str(inputCols) + ' lead to decrease in sepalLength by ' + str(linreg.coef_) + ' cm respectively')

inputCols = ['petal.length','sepal.width']
outputVariable = ['sepal.length']
X = iris[inputCols]
Y = iris[outputVariable]

linreg = LinearRegression()
linreg.fit(X, Y)
print(linreg.intercept_)
print(linreg.coef_)
print("\n")
print('sepal.length =' + str(linreg.coef_) + '*indVars + ' + str(linreg.intercept_))
print('\n')
print('Holding constant fixed, a 1 cm increase in indvars' + str(inputCols) + ' lead to decrease in sepalLength by ' + str(linreg.coef_) + ' cm respectively')

# Check for multicollinearity
import numpy as np
inputCols = ['petal.width', 'petal.length', 'sepal.width']
outputVariable = ['sepal.length']
X = iris[inputCols]
Y = iris[outputVariable]
corr = np.corrcoef(X, rowvar = 0)
print(inputCols)
print(corr)
print('\n')
print(np.linalg.det(corr))

print('\n')

inputcols = ['petal.length', 'sepal.width']
outputVariable = ['sepal.width']
X = iris[inputCols]
Y = iris[outputVariable]
Y = iris['sepal.length']
#X.drop(columns = ['sepal.length'], axis = 1)

# Split data into train/test, with 30% of data going to training
xTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size = 0.3, random_state = 12)

print(xTrain.shape) # shape shows row by col
print(xTest.shape)
print(yTrain.shape)
print(yTest.shape)

X.head()

linReg = LinearRegression()
model = linReg.fit(xTrain, yTrain)

print('R-squared for training dataset model: ', model.score(xTrain, yTrain))

# inputCols = ['petal.length', 'sepal.width'] # we are trying build reg between
# indvar petal length and depvar  sepal width
print(model.intercept_)
print(model.coef_)

predicted = model.predict(xTest)

print('MAE: ', metrics.mean_absolute_error(yTest, predicted))
print('MSE: ', metrics.mean_squared_error(yTest, predicted))
print('RMSE: ', np.sqrt(metrics.mean_squared_error(yTest, predicted)))

# Compute null RMSE
# Split into test/train
xTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size = 0.3, random_state = 12)

# Create Np array with same shape as yTest
yNull = np.zeros_like(yTest, dtype = float)

# Fill array with mean of yTest
yNull.fill(yTest.mean())
yNull

print(yTest.shape)
print(yNull.shape)

# Compute null RMSE
np.sqrt(metrics.mean_squared_error(yTest, yNull)) # we can use this as a benchmark
# we want our model to have a lower measure

featureCols = ['petal.width', 'sepal.length', 'sepal.width']

# define a function that accepts a list of features and returns testing RMSE
def trainTestRMSE(featureCols):
  X = iris[featureCols]
  Y = iris['sepal.length']
  xTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size = 0.3, random_state = 12)
  linreg = LinearRegression()
  model = linreg.fit(xTrain, yTrain)
  predicted = model.predict(xTest)
  return np.sqrt(metrics.mean_squared_error(yTest, predicted))

trainTestRMSE(featureCols) # You take this score and average with the previous score (.77)
# You can judge off of the average. This model avg (.545) did okay

print(trainTestRMSE(['petal.width', 'petal.length', 'sepal.width']))
print(trainTestRMSE(['petal.width', 'sepal.width']))
print(trainTestRMSE(['petal.length', 'sepal.width']))

# Removing sqrt to get mean squared error
def trainTestMSE(featureCols):
  X = iris[featureCols]
  Y = iris['sepal.length']
  xTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size = 0.3, random_state = 12)
  linreg = LinearRegression()
  model = linreg.fit(xTrain, yTrain)
  predicted = model.predict(xTest)
  return metrics.mean_squared_error(yTest, predicted)

print(trainTestMSE(['petal.width', 'petal.length', 'sepal.width']))
print(trainTestMSE(['petal.width', 'sepal.width']))
print(trainTestMSE(['petal.length', 'sepal.width']))

# Removing sqrt to get mean abs error
def trainTestMAE(featureCols):
  X = iris[featureCols]
  Y = iris['sepal.length']
  xTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size = 0.3, random_state = 12)
  linreg = LinearRegression()
  model = linreg.fit(xTrain, yTrain)
  predicted = model.predict(xTest)
  return metrics.mean_absolute_error(yTest, predicted)

print(trainTestMAE(['petal.width', 'petal.length', 'sepal.width']))
print(trainTestMAE(['petal.width', 'sepal.width']))
print(trainTestMAE(['petal.length', 'sepal.width']))

